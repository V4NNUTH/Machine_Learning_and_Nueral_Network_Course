{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32291272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7,   6,   7,   7,  -4,   4,   1,  -2,   9,   7],\n",
       "       [ -2,  -9,   0, -10,  -5,   6,   6,   2,  -2,   7],\n",
       "       [  1,  -1,   4,  -5,   7,  -1,   8,  -1,   6,  -5],\n",
       "       [ -3,  -3,  -5,   3,  -5,  -7,  -6,   6,   3,   4],\n",
       "       [  3,  -3,   2,   0,   5,   4,  -3,   6,   1,   8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "input_nodes = 10\n",
    "hidden_nodes = 5\n",
    "output_nodes = 7\n",
    "\n",
    "wih = np.random.randint(-10, 10,(hidden_nodes, input_nodes))\n",
    "wih"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51567fe7",
   "metadata": {},
   "source": [
    "We will choose now the active nodes for the input layer. We calculate random indices for the active nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e874e2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 5, 7, 8, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_input_percentage = 0.7\n",
    "active_input_nodes = int(input_nodes * active_input_percentage)\n",
    "active_input_indices = sorted(random.sample(range(0, input_nodes), active_input_nodes))\n",
    "\n",
    "active_input_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677f1fa",
   "metadata": {},
   "source": [
    "We learned above that we have to remove the column j, if the node ij is removed. We can easily accomplish\n",
    "this for all deactived nodes by using the slicing operator with the active nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c89bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7,   6,   7,   7,  -4,   4,   1,  -2,   9,   7],\n",
       "       [ -2,  -9,   0, -10,  -5,   6,   6,   2,  -2,   7],\n",
       "       [  1,  -1,   4,  -5,   7,  -1,   8,  -1,   6,  -5],\n",
       "       [ -3,  -3,  -5,   3,  -5,  -7,  -6,   6,   3,   4],\n",
       "       [  3,  -3,   2,   0,   5,   4,  -3,   6,   1,   8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wih_old = wih.copy()\n",
    "wih_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c3b02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7,  6, -4,  4, -2,  9,  7],\n",
       "       [-2, -9, -5,  6,  2, -2,  7],\n",
       "       [ 1, -1,  7, -1, -1,  6, -5],\n",
       "       [-3, -3, -5, -7,  6,  3,  4],\n",
       "       [ 3, -3,  5,  4,  6,  1,  8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wih = wih[:, active_input_indices]\n",
    "wih"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489787c",
   "metadata": {},
   "source": [
    "As we have mentioned before, we will have to modify both the 'wih' and the 'who' matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6db797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4   0 -10   7 -10]\n",
      " [  0   3  -8  -2  -4]\n",
      " [ -3  -3  -5  -4   1]\n",
      " [ -3   3  -6  -5   6]\n",
      " [  1   8   1  -4  -3]\n",
      " [  8   9   8   1  -7]\n",
      " [  6   4   8   1   2]]\n",
      "[0, 2, 3]\n",
      "[[ -4 -10   7]\n",
      " [  0  -8  -2]\n",
      " [ -3  -5  -4]\n",
      " [ -3  -6  -5]\n",
      " [  1   1  -4]\n",
      " [  8   8   1]\n",
      " [  6   8   1]]\n"
     ]
    }
   ],
   "source": [
    "who = np.random.randint(-10,10, (output_nodes, hidden_nodes))\n",
    "\n",
    "print(who)\n",
    "active_hidden_percentage = 0.7\n",
    "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
    "active_input_indices = sorted(random.sample(range(0, hidden_nodes), active_hidden_nodes))\n",
    "\n",
    "print(active_input_indices)\n",
    "\n",
    "who_old = who.copy()\n",
    "who = who[:, active_input_indices]\n",
    "print(who)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b516bfe",
   "metadata": {},
   "source": [
    "### Summery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d03f02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wih: \n",
      " [[ -2  -4 -10   6   7   9   4  -4  -9  -3]\n",
      " [ -3   1   4   1  -7 -10  -7  -3   0  -4]\n",
      " [ -8   5  -9   9  -8  -6   9   3   1   4]\n",
      " [ -3  -6  -4  -4  -1   8  -1  -4   4   1]\n",
      " [  5 -10  -1  -1   0  -5  -9  -9   2  -8]]\n",
      "who: \n",
      " [[-9  3  0  5  9]\n",
      " [-8  6  7  9  4]\n",
      " [-2  8  8  9 -3]\n",
      " [-2  5  0 -9 -1]\n",
      " [-6  8 -5 -3  5]\n",
      " [-7  8 -2 -7  4]\n",
      " [ 4  6 -7 -5 -3]]\n",
      "\n",
      "active input indices:  [0, 1, 2, 3, 5, 6, 7]\n",
      "active hidden indices:  [0, 1, 2, 3, 5, 6, 7]\n",
      "\n",
      "wih after deactivating input nodes:\n",
      " [[ -2  -4 -10   6   9   4  -4]\n",
      " [ -3   1   4   1 -10  -7  -3]\n",
      " [ -8   5  -9   9  -6   9   3]\n",
      " [ -3  -6  -4  -4   8  -1  -4]\n",
      " [  5 -10  -1  -1  -5  -9  -9]]\n",
      "\n",
      "wih after deactivating hidden nodes:\n",
      " [[ -2  -4 -10   6   9   4  -4]\n",
      " [ -3   1   4   1 -10  -7  -3]\n",
      " [ -3  -6  -4  -4   8  -1  -4]]\n",
      "\n",
      "wih after deactivating hidden nodes:\n",
      " [[-9  3  5]\n",
      " [-8  6  9]\n",
      " [-2  8  9]\n",
      " [-2  5 -9]\n",
      " [-6  8 -3]\n",
      " [-7  8 -7]\n",
      " [ 4  6 -5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "input_nodes = 10\n",
    "hidden_nodes = 5\n",
    "output_notes = 7\n",
    "\n",
    "wih = np.random.randint(-10, 10, (hidden_nodes, input_nodes))\n",
    "print(\"wih: \\n\", wih)\n",
    "who = np.random.randint(-10, 10,(output_nodes, hidden_nodes))\n",
    "print(\"who: \\n\", who)\n",
    "\n",
    "active_input_percentage = 0.7\n",
    "active_hidden_percentage = 0.7\n",
    "\n",
    "active_input_nodes = int(input_nodes * active_input_percentage)\n",
    "active_input_indices = sorted(random.sample(range(0, input_nodes), active_input_nodes))\n",
    "\n",
    "print(\"\\nactive input indices: \", active_input_indices)\n",
    "active_hidden_nodes = int(hidden_nodes * active_hidden_percentage)\n",
    "active_hidden_indices = sorted(random.sample(range(0, hidden_nodes),active_hidden_nodes))\n",
    "\n",
    "print(\"active hidden indices: \", active_input_indices)\n",
    "\n",
    "wih_old = wih.copy()\n",
    "wih = wih[:, active_input_indices]\n",
    "print(\"\\nwih after deactivating input nodes:\\n\", wih)\n",
    "wih = wih[active_hidden_indices]\n",
    "print(\"\\nwih after deactivating hidden nodes:\\n\", wih)\n",
    "\n",
    "who_old = who.copy()\n",
    "who = who[:, active_hidden_indices]\n",
    "print(\"\\nwih after deactivating hidden nodes:\\n\", who)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6adf1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,\n",
    "                no_of_in_nodes,\n",
    "                no_of_out_nodes,\n",
    "                no_of_hidden_nodes,\n",
    "                learning_rate,\n",
    "                bias=None\n",
    "                ):\n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.bias = bias\n",
    "        self.create_weight_matrices()\n",
    "\n",
    "    def create_weight_matrices(self):\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        \n",
    "        n = (self.no_of_in_nodes + bias_node) * self.no_of_hidden_nodes\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        \n",
    "        self.wih = X.rvs(n).reshape((self.no_of_hidden_nodes,self.no_of_in_nodes + bias_node))\n",
    "        n = (self.no_of_hidden_nodes + bias_node) * self.no_of_out_nodes\n",
    "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
    "        self.who = X.rvs(n).reshape((self.no_of_out_nodes,(self.no_of_hidden_nodes + bias_node)))\n",
    "\n",
    "    def dropout_weight_matrices(self,\n",
    "        active_input_percentage=0.70,\n",
    "        active_hidden_percentage=0.70):\n",
    "        # restore wih array, if it had been used for dropout\n",
    "        self.wih_orig = self.wih.copy()\n",
    "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
    "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
    "        self.who_orig = self.who.copy()\n",
    "        \n",
    "        active_input_nodes = int(self.no_of_in_nodes * active_input_percentage)\n",
    "        active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes),active_input_nodes))\n",
    "        active_hidden_nodes = int(self.no_of_hidden_nodes * active_hidden_percentage)\n",
    "        active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes),active_hidden_nodes))\n",
    "        self.wih = self.wih[:, active_input_indices][active_hidden_indices]\n",
    "        self.who = self.who[:, active_hidden_indices]\n",
    "        self.no_of_hidden_nodes = active_hidden_nodes\n",
    "        self.no_of_in_nodes = active_input_nodes\n",
    "        \n",
    "        return active_input_indices, active_hidden_indices\n",
    "    \n",
    "    def weight_matrices_reset(self,\n",
    "                                active_input_indices,\n",
    "                                active_hidden_indices):\n",
    "        \"\"\"\n",
    "        self.wih and self.who contain the newly adapted values fro\n",
    "        m the active nodes.\n",
    "        We have to reconstruct the original weight matrices by ass\n",
    "        igning the new values\n",
    "        from the active nodes\n",
    "        \"\"\"\n",
    "        temp = self.wih_orig.copy()[:,active_input_indices]\n",
    "        temp[active_hidden_indices] = self.wih\n",
    "\n",
    "        self.wih_orig[:, active_input_indices] = temp\n",
    "        self.wih = self.wih_orig.copy()\n",
    "        self.who_orig[:, active_hidden_indices] = self.who\n",
    "        self.who = self.who_orig.copy()\n",
    "        self.no_of_in_nodes = self.no_of_in_nodes_orig\n",
    "        self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n",
    "\n",
    "    def train_single(self, input_vector, target_vector):\n",
    "        \"\"\"\n",
    "        input_vector and target_vector can be tuple, list or ndarray\n",
    "        \"\"\"\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the input_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "        \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        \n",
    "        output_vector1 = np.dot(self.wih, input_vector)\n",
    "        output_vector_hidden = activation_function(output_vector1)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector_hidden = np.concatenate( (output_vector_hidden, [[self.bias]]) )\n",
    "        \n",
    "        output_vector2 = np.dot(self.who, output_vector_hidden)\n",
    "        output_vector_network = activation_function(output_vector2)\n",
    "        output_errors = target_vector - output_vector_network\n",
    "       \n",
    "        # update the weights:\n",
    "        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)\n",
    "        tmp = self.learning_rate * np.dot(tmp, output_vector_hidden.T)\n",
    "        \n",
    "        self.who += tmp \n",
    "        \n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n",
    "        if self.bias:\n",
    "            x = np.dot(tmp, input_vector.T)[:-1,:]\n",
    "        else:\n",
    "            x = np.dot(tmp, input_vector.T)\n",
    "            \n",
    "        self.wih += self.learning_rate * x\n",
    "        \n",
    "    def train(self, data_array,\n",
    "            labels_one_hot_array,\n",
    "            epochs=1,\n",
    "            active_input_percentage=0.70,\n",
    "            active_hidden_percentage=0.70,\n",
    "            no_of_dropout_tests = 10):\n",
    "        partition_length = int(len(data_array) / no_of_dropout_tests)\n",
    "        for epoch in range(epochs):\n",
    "            print(\"epoch: \", epoch)\n",
    "            for start in range(0, len(data_array), partition_length):\n",
    "                active_in_indices, active_hidden_indices = self.dropout_weight_matrices(active_input_percentage,active_hidden_percentage)\n",
    "                for i in range(start, start + partition_length):\n",
    "                    self.train_single(data_array[i][active_in_indices],labels_one_hot_array[i])\n",
    "                self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n",
    "                \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = {}\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            if (target, res_max) in cm:\n",
    "                cm[(target, res_max)] += 1\n",
    "            else:\n",
    "                cm[(target, res_max)] = 1\n",
    "        return cm\n",
    "    \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the input_vector\n",
    "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
    "        \n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        output_vector = np.dot(self.wih, input_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        if self.bias:\n",
    "            output_vector = np.concatenate( (output_vector, [[self.bias]]) )\n",
    "        \n",
    "        output_vector = np.dot(self.who, output_vector)\n",
    "        output_vector = activation_function(output_vector)\n",
    "        \n",
    "        return output_vector\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc45bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "0 6000\n",
      "6000 12000\n",
      "12000 18000\n",
      "18000 24000\n",
      "24000 30000\n",
      "30000 36000\n",
      "36000 42000\n",
      "42000 48000\n",
      "48000 54000\n",
      "54000 60000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/mnist/pickled_mnist.pkl\", \"br\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "    \n",
    "train_imgs = data[0]\n",
    "test_imgs = data[1]\n",
    "train_labels = data[2]\n",
    "test_labels = data[3]\n",
    "train_labels_one_hot = data[4]\n",
    "test_labels_one_hot = data[5]\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 # i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "\n",
    "parts = 10\n",
    "partition_length = int(len(train_imgs) / parts)\n",
    "print(partition_length)\n",
    "\n",
    "start = 0\n",
    "for start in range(0, len(train_imgs), partition_length):\n",
    "    print(start, start + partition_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a8f2a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "simple_network = NeuralNetwork(no_of_in_nodes = image_pixels,\n",
    "                            no_of_out_nodes = 10,\n",
    "                            no_of_hidden_nodes = 100,\n",
    "                            learning_rate = 0.1)\n",
    "\n",
    "simple_network.train(train_imgs,\n",
    "                    train_labels_one_hot,\n",
    "                    active_input_percentage=1,\n",
    "                    active_hidden_percentage=1,\n",
    "                    no_of_dropout_tests = 100,\n",
    "                     epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fadd25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train:  0.9093333333333333\n",
      "accuracy: test 0.9095\n"
     ]
    }
   ],
   "source": [
    "corrects, wrongs = simple_network.evaluate(train_imgs, train_labels)\n",
    "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = simple_network.evaluate(test_imgs, test_labels)\n",
    "print(\"accuracy: test\", corrects / ( corrects + wrongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75aee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
