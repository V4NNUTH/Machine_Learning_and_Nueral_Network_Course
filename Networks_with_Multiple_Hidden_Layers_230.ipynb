{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72775fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as activation_function\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm((low - mean) / sd,\n",
    "                    (upp - mean) / sd,\n",
    "                    loc = mean,\n",
    "                    scale=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfb5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,\n",
    "                network_structure,\n",
    "                leaarning_rate,\n",
    "                bias = None):\n",
    "        self.structure = network_structure\n",
    "        self.learning_rate = leaarning_rate\n",
    "        self.bias = bias\n",
    "        self.create_weight_metrices()\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []\n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        while layer_index < no_of_layers:\n",
    "            nodes_in = self.structure[layer_index-1]\n",
    "            nodes_out = self.structure[layer_index]\n",
    "            n = (nodes_in + bias_node) * nodes_out\n",
    "            rad = 1 / np.sqrt(nodes_in)\n",
    "            X = truncated_normal(mean=2,\n",
    "                                sd=1,\n",
    "                                low=-rad,\n",
    "                                upp=rad)\n",
    "            wm = X.rvs(n).reshape((nodes_out, nodes_in + bias_node))\n",
    "            self.weights_matrices.append(wm)\n",
    "            layer_index += 1\n",
    "            \n",
    "    def train(self, input_vector, target_vector):\n",
    "        \"\"\"\n",
    "        input_vector and target_vector can be tuple,\n",
    "        list or ndarray\n",
    "        \"\"\"\n",
    "        no_of_layers = len(self.structure)\n",
    "        input_vector = np.array(input_vector, ndmin=2).T\n",
    "        layer_index = 0\n",
    "        \n",
    "        # The output/input vectors of the various layers:\n",
    "        res_vectors = [input_vector]\n",
    "        while layer_index < no_of_layers - 1:\n",
    "            in_vector = res_vectors[-1]\n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                in_vector = np.concatenate( (in_vector,[[self.bias]]) )\n",
    "                res_vectors[-1] = in_vector\n",
    "            x = np.dot(self.weights_matrices[layer_index],in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            # the output of one layer is the input of the next one:\n",
    "            res_vectors.append(out_vector)\n",
    "            layer_index += 1\n",
    "            \n",
    "        layer_index = no_of_layers - 1\n",
    "        target_vector = np.array(target_vector, ndmin=2).T\n",
    "        # The input vectors to the various layers\n",
    "        output_errors = target_vector - out_vector\n",
    "        \n",
    "        while layer_index > 0:\n",
    "            out_vector = res_vectors[layer_index]\n",
    "            in_vector = res_vectors[layer_index-1]\n",
    "            if self.bias and not layer_index==(no_of_layers-1):\n",
    "                out_vector = out_vector[:-1,:].copy()\n",
    "            tmp = output_errors * out_vector * (1.0 - out_vector)\n",
    "            tmp = np.dot(tmp, in_vector.T)\n",
    "            #if self.bias:\n",
    "            # tmp = tmp[:-1,:]\n",
    "            self.weights_matrices[layer_index-1] += self.learning_rate * tmp\n",
    "            output_errors = np.dot(self.weights_matrices[layer_index-1].T,output_errors)\n",
    "            if self.bias:\n",
    "                output_errors = output_errors[:-1,:]\n",
    "            layer_index -= 1\n",
    "            \n",
    "    def run(self, input_vector):\n",
    "        # input_vector can be tuple, list or ndarray\n",
    "        no_of_layers = len(self.structure)\n",
    "        if self.bias:\n",
    "            # adding bias node to the end of the inpuy_vector\n",
    "            input_vector = np.concatenate( (input_vector,[self.bias]) )\n",
    "        in_vector = np.array(input_vector, ndmin=2).T\n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        while layer_index < no_of_layers:\n",
    "            x = np.dot(self.weights_matrices[layer_index-1],in_vector)\n",
    "            out_vector = activation_function(x)\n",
    "            # input vector for next layer\n",
    "            in_vector = out_vector\n",
    "            if self.bias:\n",
    "                in_vector = np.concatenate((in_vector,[[self.bias]]))\n",
    "                \n",
    "            layer_index += 1\n",
    "            \n",
    "        return out_vector\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i]:\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN = NeuralNetwork(network_structure=[image_pixel, 50, 50, 10],\n",
    "                   learning_rate=0.1,\n",
    "                   bias=None)\n",
    "\n",
    "for i in range(len(train_imgs)):\n",
    "    ANN.train(train_imgs[i], train_labels_one_hot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57389505",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\n",
    "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
    "corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\n",
    "print(\"accuracy: test\", corrects / ( corrects + wrongs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
